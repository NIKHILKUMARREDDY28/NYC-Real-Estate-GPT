from openai import AsyncOpenAI, OpenAI
import instructor
from pydantic import BaseModel, Field

from streamlit_app.config import settings


openai_client = OpenAI(api_key=f"{settings.OPENAI_API_KEY}")
patched_openai = instructor.patch(openai_client)

ollama_client = OpenAI(base_url=f"{settings.OLLAMA_API_URL}", api_key="ollama")
patched_ollama_client = instructor.patch(ollama_client)

class HumanResponse(BaseModel):
    chain_of_thought: str = Field(..., title="Chain of Thought", description="The chain of thought leading to the response.")
    response: str = Field(..., title="Response", description="The response generated by the model.")

class OpenAILLMSClient:
    def __init__(self):
        self.patched_client = patched_openai
        self.client = openai_client

    def get_answer(self, messages: list):
        response =  self.patched_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.0,
            max_retries=3,
            response_model=HumanResponse
        )
        return response.response

    def get_embedding(self, text: str):
        response = self.client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding


class OllamaLLMSClient:
    def __init__(self):
        self.patched_client = patched_ollama_client


    def get_answer(self, messages: list):
        response =  self.patched_client.chat.completions.create(
            model="llama3.1:8b",
            messages=messages,
            temperature=0.0,
            max_retries=3,
            response_model=HumanResponse
        )
        return response.response

if __name__ == '__main__':
    import asyncio
    ollama_client = OllamaLLMSClient()
    ollama_client.get_answer([{"role":"user","content":"What is the capital of France?"}])
