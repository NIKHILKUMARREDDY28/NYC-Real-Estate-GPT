from openai import AsyncOpenAI
import instructor
from pydantic import BaseModel, Field

from streamlit_app.config import settings

patched_openai = instructor.patch(AsyncOpenAI(api_key=settings.OPENAI_API_KEY))
patched_ollama_client = instructor.patch(AsyncOpenAI(base_url=f"{settings.OLLAMA_API_URL}", api_key="ollama"))

class HumanResponse(BaseModel):
    chain_of_thought: str = Field(..., title="Chain of Thought", description="The chain of thought leading to the response.")
    response: str = Field(..., title="Response", description="The response generated by the model.")

class OpenAILLMSClient:
    def __init__(self, openai_api_key: str):
        self.patched_client = patched_openai

    async def get_answer(self, messages: list):
        response = await self.patched_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.0,
            max_retries=3,
            response_model=HumanResponse
        )
        return response.response


class OllamaLLMSClient:
    def __init__(self):
        self.patched_client = patched_ollama_client


    async def get_answer(self, messages: list):
        response = await self.patched_client.chat.completions.create(
            model="llama3.1:8b",
            messages=messages,
            temperature=0.0,
            max_retries=3,
            response_model=HumanResponse
        )
        return response.response

if __name__ == '__main__':
    import asyncio
    ollama_client = OllamaLLMSClient()
    print(asyncio.run(ollama_client.get_answer([{"role":"user","content":"What is the capital of France?"}])))
