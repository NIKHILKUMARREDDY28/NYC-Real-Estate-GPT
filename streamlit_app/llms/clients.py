from openai import AsyncOpenAI, OpenAI
import instructor
from pydantic import BaseModel, Field

from streamlit_app.config import settings


openai_client = OpenAI(api_key=f"{settings.OPENAI_API_KEY}")
patched_openai = instructor.patch(openai_client)

ollama_client = OpenAI(base_url=f"{settings.OLLAMA_API_URL}", api_key="ollama")
patched_ollama_client = instructor.patch(ollama_client)

class HumanResponse(BaseModel):
    chain_of_thought: str = Field(..., title="Chain of Thought", description="The chain of thought leading to the response.")
    response: str = Field(..., title="Response", description="The response generated by the model.")

SYSTEM_PROMPT = """
You are an AI Assistant specialized in NYC real estate, with access to a Retrieval-Augmented Generation (RAG) pipeline connected to the ACRIS dataset. Your job is to:

Interpret user queries about NYC propertiesâ€”such as ownership details, permit requirements, or historical transactions.
Retrieve relevant property records from the ACRIS dataset by leveraging your RAG pipeline (vector store or structured index).
Generate human-friendly answers that clearly and accurately address user questions. Where applicable, provide:
Ownership information (names, companies, etc.)
Transaction history or important dates
Permit details or references to city regulations
Disclaimers on data currency and completeness
Request clarification from the user if the query is ambiguous or missing details.
Maintain an engaging, professional tone by organizing your answers into clear sections, including bullet points or headings to highlight critical details.
Acknowledge data gaps if certain information is unavailable and suggest next steps (e.g., verifying city records, providing additional query details).
Guidelines:

Always verify you are pulling data from the relevant property records in the ACRIS dataset.
Stay concise and correct; if you are unsure about an answer, provide disclaimers or clarify that the information might need confirmation.
Cite relevant document IDs or references briefly if available, but do not overwhelm the user with excessive technical details.
Avoid speculation beyond the data in the ACRIS records. Provide factual, accurate responses with a neutral but friendly tone.
"""

class OpenAILLMSClient:
    def __init__(self):
        self.patched_client = patched_openai
        self.client = openai_client

    def get_answer(self, messages: list):
        response =  self.patched_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role":"system","content":SYSTEM_PROMPT}] + messages,
            temperature=0.0,
            max_retries=3,
            response_model=HumanResponse,
            seed=42
        )
        return response.response

    def get_embedding(self, text: str):
        response = self.client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding


class OllamaLLMSClient:
    def __init__(self):
        self.patched_client = patched_ollama_client


    def get_answer(self, messages: list):
        response =  self.patched_client.chat.completions.create(
            model="llama3.1:8b",
            messages=messages,
            temperature=0.0,
            max_retries=3,
            response_model=HumanResponse
        )
        return response.response

if __name__ == '__main__':
    import asyncio
    ollama_client = OllamaLLMSClient()
    ollama_client.get_answer([{"role":"user","content":"What is the capital of France?"}])
